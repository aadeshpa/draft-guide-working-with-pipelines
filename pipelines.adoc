---
permalink: /guides/pipelines-getting-started/
---
:page-layout: guide
:page-duration: 30 minutes
:page-releasedate: 2019-10-17
:page-description: Explore how to use Kabanero Pipelines to build and manage Kabanero collections.
:page-tags: ['Collection']
:page-guide-category: pipelines

== Working with Kabanero Pipelines

Kabanero uses link:https://github.com/tektoncd/pipeline/tree/master/docs#usage[Tekton Pipelines] to illustrate a CI/CD workflow. Each of the featured link:https://github.com/kabanero-io/collections[Kabanero collections] contains a default pipeline that builds the collection, publishes the image to a docker repo, and then deploys the image to the Kubernetes cluster. You can add more tasks and pipelines to the collections. All the tasks and pipelines are activated by the link:https://github.com/kabanero-io/kabanero-operator[Kabanero operator].

To learn more about Tekton Pipelines and creating new tasks, see link:https://github.com/tektoncd/pipeline/blob/master/docs/tutorial.md[the Tekton Pipeline tutorial].

== Kabanero Tasks and Pipelines

Each Kabanero collection contains default tasks & pipelines that are created when the collection is built. Currently,  all the featured collections share tasks & pipelines. The collections build process copies the files from link:https://github.com/kabanero-io/collections/tree/master/incubator/common/pipelines/default[the collections repo] to your `/pipelines` directory.

If you are building a new collection, you can use these existing pipelines as they are if that satisfies your requirements to build and deploy. They are automatically pulled into your collection when you build your collections repo. If you want to change the tasks or pipelines, you can choose to have your changes apply either to all collections or a specific collection.  To apply your changes to all the collections,  update the files in the `incubator/common/pipelines/default` in your collections repo. If you want to update tasks or pipelines in a particular collection, create the files in the pipelines directory under that collection in your collections
repo.

=== The build and deploy pipeline

link:https://github.com/kabanero-io/collections/blob/master/incubator/common/pipelines/default/build-deploy-pipeline.yaml[Build-deploy-pipeline.yaml]

This file is the primary pipeline that is associated with the collections. It validates that the collection is active, builds the Git source, publishes the container image, and deploys the application. It looks for `git-source` and `docker-image` resources that are used by the `build-task` and `deploy-task` files.

=== Tasks

- link:https://github.com/kabanero-io/collections/blob/master/incubator/common/pipelines/default/build-task.yaml[`Build-task.yaml`]

This file builds a container image from the artifacts in the git-source repository by using link:https://github.com/containers/buildah[Buildah]. After the image is built, the `build-task` file publishes it to the docker-image URL by using Buildah.

- link:https://github.com/kabanero-io/collections/blob/master/incubator/common/pipelines/default/build-task.yaml[`Deploy-task.yaml`]

This file modifies the `app-deploy.yaml` file, which describes the deployment options for the application. `Deploy-task` modifies `app-deploy.yaml` to point to the image that was published and deploys the application by using the Appsody operator. Generate your `app-deploy.yaml` file by running the `appsody deploy --generate-only` command.

By default, the pipelines run and deploy the application in the `+kabanero+` namespace. If you want to deploy the application in a different namespace, update the `app-deploy.yaml` file to point to that namespace.

For more information, see link:https://github.com/kabanero-io/kabanero-pipelines[the kabanero-pipelines repo].

== Running the pipelines

=== Prerequisites

. link:https://github.com/kabanero-io/kabanero-foundation[Kabanero foundation] must be installed on Red Hat Origin Community Distribution of Kubernetes (OKD) or the OpenShift Container Platform (OCP) cluster.

. link:https://github.com/tektoncd/dashboard[Tekton Dashboard] is installed by default with Kabanero Foundation. To find the Tekton Dashboard URL, login to your OKD cluster and run `+oc get routes+` or check in the OKD console.



==== Set up dynamic volume provisioning or a persistent volume.

Tekton pipelines require a configured volume that is used by the framework to share data across tasks. The build task, which uses Buildah, also requires a volume mount. The minimum required volume size is five Gi.

If your cluster is running in a public cloud, dynamic volume provisioning is the easier and preferred option. For more information, see link:https://github.com/tektoncd/pipeline/blob/master/docs/install.md#how-are-resources-shared-between-tasks[How are resources shared between tasks].

Your persistent volume must be configured based on how your cloud provider’s default storage class is configured. Otherwise, your pipelines might create a new volume for each run, which increases your pipeline run execution time.

Alternatively, if you are using an unmanaged cluster, you can set up a persistent volume to be used by the pipeline. A simple example pv definition is provided in the following example. Update the path and other values in your `pv.yaml` file to suit your requirements. For instance, NFS is the preferred configuration in a production environment, rather than using local storage, as shown in the example.

. Log in to your cluster. For example, for OKD:

```
oc login <master node IP>:8443
```

. Clone the `pv.yaml` file in this repo and apply it.

```
cd ./pipelines/common
oc apply -f pv.yaml -n kabanero
```

==== Create secrets

Git secrets must be created in the `+kabanero+` namespace and associated with the service account that runs the pipelines. To configure secrets by using the Tekton Dashboard, see
link:https://kabanero.io/docs/ref/general/tekton-webhooks.html#create-secrets[Create secrets].

Alternatively, you can configure secrets in the OKD console or you can set up the secret by using the OKD CLI.



=== Execute pipelines by using the Tekton Dashboard Webhook Extension

You can link:https://kabanero.io/docs/ref/general/tekton-webhooks.html[use the Tekton Dashboard Webhook Extension to drive pipelines] that automatically build and deploy an application whenever you update the code in your Git repo. Events such as commits or pull requests can be set up to automatically trigger pipeline runs.

=== Manual pipeline execution using a script

If you are developing a new pipeline and want to manually test it in a tight loop, you might want to use a script or manually drive the pipeline.

. Log in to your cluster. For example for OKD,

```
oc login <master node IP>:8443
```

. Clone the kabanero pipelines repo

```
git clone https://github.com/kabanero-io/kabanero-pipelines
```

. Run the following script with the appropriate parameters

```
cd ./pipelines/incubator/manual-pipeline-runs/

./manual-pipeline-run-script.sh -r [git_repo of the Appsody project] -i [docker registery path of the image to be created] -c [collections name of which pipeline to be run]"
```

For example:

```
./manual-pipeline-run-script.sh -r https://github.com/mygitid/appsody-test-project -i index.docker.io/mydockeid/my-java-microprofile-image -c java-microprofile"
```

=== Manual pipeline execution from the command line

. Login to your cluster. For example for OKD,

```
oc login <master node IP>:8443
```

. Clone the kabanero pipelines repo

```
git clone https://github.com/kabanero-io/kabanero-pipelines
cd kabanero-pipelines
```

. Create Pipeline resources

Update the `pipeline-resources.yaml` file with your GitHub & Docker repo information to create the `PipelineResources`. Sample `pipeline-resources.yaml` files are provided for each featured collection in the `manual-pipeline-runs` directory. Update the docker-image URL. You can use the sample GitHub rep or update it to point to your own GitHub repo.

. After you update the file, apply it.

```
oc apply -f <collection-name>-pipeline-resources.yaml
```

==== Activate tasks & pipelines

The installations that activate the featured collections also activate the tasks and pipelines. If you are creating a new task or pipeline, activate it manually, as shown in the following example.

```
oc apply -f <task.yaml>
oc apply -f <pipeline.yaml>
```

==== Run the pipeline

Sample PipelineRun files are provided under `./pipelines/manual-pipeline-runs`. Locate the appropriate pipeline-run
file and execute it, as shown in the following example.

```
oc apply -f <collection-name>-pipeline-run.yaml
```

== Checking the status of the pipeline run

You can check the status of the pipeline run from the OKD console,
command line, or Tekton dashboard.

=== Checking pipeline run status from the Tekton dashboard

. Log in to the Tekton Dashboard and click `Pipeline runs'
in the sidebar menu.

. Find your pipeline run in the list and click it to check the status and find logs. You can see logs
and status of each step and task.

=== Checking pipeline run status from the command line:

Enter the following command in the terminal

```
oc get pipelineruns
oc -n kabanero describe pipelinerun.tekton.dev/<pipeline-run-name>
```

You should also see pods for the pipeline runs that you can specify `+oc describe+` and `+oc logs+` for to get more details

If the pipeline run was successful, you should see a docker image in our docker registry and a pod that’s running your application.

== Troubleshooting

To find solutions for common issues and troubleshoot problems with pipelines, see the link:https://github.com/kabanero-io/kabanero-pipelines/blob/master/Troubleshooting.md[Kabanero Pipelines Troubleshooting Guide].
